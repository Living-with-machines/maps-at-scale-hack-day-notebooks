{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is transfer learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transfer learning is one of the techniques we will use to help reduce the amount of training data we require. \n",
    "- Intuitively we can think of transfer learning as leveraging information a network has learned on one set of data for another set of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does it help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to aid with reproducibility \n",
    "np.random.seed(42)\n",
    "# Batch size \n",
    "bs = 64\n",
    "sz = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/maps'),\n",
       " PosixPath('data/railway_training_compressed'),\n",
       " PosixPath('data/101101394.1.tiff'),\n",
       " PosixPath('data/.DS_Store'),\n",
       " PosixPath('data/Maps-railway-training'),\n",
       " PosixPath('data/Sample_OS_town_plans_London_1890s_compressed.zip'),\n",
       " PosixPath('data/OS_town_plans_London_1890s'),\n",
       " PosixPath('data/maps-railway-training.zip'),\n",
       " PosixPath('data/.ipynb_checkpoints'),\n",
       " PosixPath('data/Sample_OS_town_plans_London_1890s_compressed')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('data')\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (ImageDataBunch.from_folder(path/'railway_training_compressed', train='.', valid_pct=0.2, size=sz, bs=bs, num_workers=4)\n",
    "        .normalize(imagenet_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (511 items)\n",
       "x: ImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "y: CategoryList\n",
       "01_rail,01_rail,01_rail,01_rail,01_rail\n",
       "Path: data/railway_training_compressed;\n",
       "\n",
       "Valid: LabelList (127 items)\n",
       "x: ImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "y: CategoryList\n",
       "01_rail,01_rail,01_rail,02_no_rail,02_no_rail\n",
       "Path: data/railway_training_compressed;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without transfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet18, pretrained=False, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.956517</td>\n",
       "      <td>0.783459</td>\n",
       "      <td>0.464567</td>\n",
       "      <td>06:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.694682</td>\n",
       "      <td>0.785306</td>\n",
       "      <td>0.480315</td>\n",
       "      <td>06:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.567375</td>\n",
       "      <td>0.980732</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>06:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.467717</td>\n",
       "      <td>0.883268</td>\n",
       "      <td>0.488189</td>\n",
       "      <td>06:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.375018</td>\n",
       "      <td>0.859817</td>\n",
       "      <td>0.385827</td>\n",
       "      <td>06:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_pre_trained = cnn_learner(data, models.resnet18, pretrained=True, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [1/5 06:03<24:15]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.973549</td>\n",
       "      <td>0.643150</td>\n",
       "      <td>0.354331</td>\n",
       "      <td>06:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='7', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      14.29% [1/7 02:07<12:43 0.9486]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_pre_trained.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning \n",
    "\n",
    "We've looked at the impact of switching 'pretraining' on or off but what does this actually do?\n",
    "\n",
    "## ImageNet\n",
    "\n",
    "- This option defines whether the cnn we create has been pre-trained on imagenet \n",
    "\n",
    "### What is imagenet and what is the network pre-trained to do?\n",
    "- '[ImageNet](http://www.image-net.org/) is an image database organized according to the WordNet hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images.' [Source](http://www.image-net.org/)\n",
    "\n",
    "- 'Based on statistics about the dataset recorded on the ImageNet homepage, there are a little more than 14 million images in the dataset, a little more than 21 thousand groups or classes (synsets), and a little more than 1 million images that have bounding box annotations (e.g. boxes around identified objects in the images).The photographs were annotated by humans using crowdsourcing platforms such as Amazonâ€™s Mechanical Turk.' [Source](https://machinelearningmastery.com/introduction-to-the-imagenet-large-scale-visual-recognition-challenge-ilsvrc/)\n",
    "\n",
    "- Our network has been pre-trained to classify images into categories i.e. dog, cat, train, car, flower...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the network learning?\n",
    "- It might seem strange that Imagenet will help us help find train tracks or buildings in historic os maps which it has never 'seen' before. \n",
    "- To explain this we need to develop some intuation about what a network is 'learning'\n",
    "- Let's look through a dicussion of this [here](https://github.com/hiromis/notes/blob/master/Lesson1.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benefits of using transfer learning\n",
    "- Training dataset can be much smaller \n",
    "- Improved accuracy \n",
    "- Cost of training reduced \n",
    "- Speed of convergence quicker \n",
    "- [Environmental costs reduced](https://www.technologyreview.com/s/613630/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning and digital humanities? \n",
    "- Quantify impact of transfer learning for DH \n",
    "- We might want to think about what possible impact transfer learning has in a dh context more closely?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP and transfer learning (sidenote)\n",
    "- Transfer learning has recently become much more widely used in NLP tasks, particularly for language models. \n",
    "- Language models training on a general corpus are fine-tuned on the domain specific corpus \n",
    "- These language models can then be utilised in downstream tasks like text classification, NER etc. \n",
    "- These approaches mean you can often get good accuracy on a classification model with <200 labels. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:maps]",
   "language": "python",
   "name": "conda-env-maps-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
