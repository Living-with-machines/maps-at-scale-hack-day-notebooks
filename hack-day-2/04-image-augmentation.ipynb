{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What?\n",
    "\n",
    "Image augmentation applies various transformations to the images in our training data including;\n",
    "- random zoom\n",
    "- flip (vertical/horizontal) \n",
    "- blur\n",
    "- contrast\n",
    "- plus many more\n",
    "\n",
    "These transformations are usually performed with some probability i.e. they won't always be applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why might we want to use transforms?\n",
    "\n",
    "One of the early assertions made in these notebooks is that we don't necessarily need as much training data for deep learning as is often presumed. One of the reasons for this is transfer learning. Another important reason is image augmentation. \n",
    "\n",
    "For example: \n",
    "\n",
    "![Cat picture flipped](figures/cat.png)\n",
    "\n",
    "In the above we have a picture of a cat flipped. Now we double the potential pictures to show the network and since we already know it is a picture of a cat we don't need to annotate the data twice. Image transforms allow us to 'augment' our data i.e. artificially create more examples without having to collect more training data and label it. \n",
    "There are some caveats though..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image transforms for maps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cat picture with various brightness levels](figures/cat_brightness.png) \n",
    "\n",
    "# ! Discussion \n",
    "- why might this transform not make sense for us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using transforms \n",
    "\n",
    "We can easily use a range of vision transforms within fastai. See documentation for guidance \n",
    "\n",
    "- https://docs.fast.ai/vision.transform.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! Test transforms \n",
    "- It would be really useful to know which vision transforms help with maps \n",
    "- Some are likely to help i.e. rotation, but others might not since the maps are captured in a controlled environment so won't have photographic artifacts. \n",
    "- Other disciplines have explored this question see: [x-ray imaging](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10574/105741M/Chest-x-ray-generation-and-data-augmentation-for-cardiovascular-abnormality/10.1117/12.2293971.short?SSO=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixup \n",
    "\n",
    "Some image transformations are less intuitive but can be very effective. \n",
    "\n",
    "- mixup [arXiv:1710.09412](https://arxiv.org/abs/1710.09412)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggested workflow\n",
    "- load some data annotated previously\n",
    "- Apply one or more transforms from fastai\n",
    "- Train network\n",
    "- compare to using same data/training process for other types of augmentations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New transforms\n",
    "- We can pass arbitrary transformations to fastai so we don't need to stick with ones included. If you are feeling ambitious you could create new transformations building on skills learned from hack day 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
